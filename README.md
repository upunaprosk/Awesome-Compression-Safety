# Compression Side Effects [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

Quantization and other model compression techniques significantly improve efficiency, but may also compromise trustworthiness, fairness, and overall model reliability.

This repository provides a **curated list of papers, benchmarks, and resources** exploring the *undesired side effects* of model compression — particularly focusing on its impact on:

- **Fairness**  
- **Robustness**  
- **Calibration**  
- **Toxicity and safety**

<p align="center">
  <img src="https://github.com/upunaprosk/Awesome-Compression-Safety/blob/master/figure-Page-2.png" alt="Compression Side Effects" width="400">
</p>



## Paper list

| Title | Link |
|-------|------|
| **Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression** (ICML 2024) | [arXiv](https://arxiv.org/abs/2403.15447) |
| **Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression** (EMNLP Findings 2024) | [ACL Anthology](https://aclanthology.org/2024.findings-emnlp.901/) |
| **Benchmarking Post-Training Quantization in LLMs: A Comprehensive Taxonomy** (Feb 2025) | [arXiv](https://arxiv.org/abs/2502.13178) |
| **A Comprehensive Evaluation of Quantization Strategies for Large Language Models** (ACL Findings 2024) | [ACL Anthology](https://aclanthology.org/2024.findings-acl.726/) |
| **BiLLM: Pushing the Limit of Post-Training Quantization for LLMs** (Feb 2024) | [arXiv](https://arxiv.org/abs/2402.04291) |
| **When Quantization Affects Confidence of Large Language Models?** (NAACL Findings 2024) | [ACL Anthology](https://aclanthology.org/2024.findings-naacl.124/) |
| **On the Impact of Calibration Data in Post‑Training Quantization and Pruning** (ACL 2023) | [arXiv](https://arxiv.org/abs/2311.09755) |
| **Self‑calibration for Language Model Quantization and Pruning** (NAACL 2025) | [arXiv](https://arxiv.org/abs/2410.17170) |
| **How Does Quantization Affect Multilingual LLMs?** (EMNLP Findings 2024)| [ACL Anthology](https://aclanthology.org/2024.findings-emnlp.935/) |

